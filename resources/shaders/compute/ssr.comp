layout(std140, binding = 1) uniform UniformBlock
{
	float zThickness; // How thick is each depth fragment? higher value yields some wierd smudging at edges of reflection, but thinner z means we might miss some geometry. This should essentially be the average thickness of the geometry. to do dynamically would be a nightmare however...
	float stride; // lets you skip pixels during iteration. Larger stride means longer rays with same number of samples.
	float jitter; // if stride > 1 we ge banding results. This can be traded for noise by jittering the start position of each ray.
	float maxSteps; //Less steps means shorter reflections, but better performance
	float maxDistance; //Not orthogonal to max steps. reflection of surfaces far away in world space are prone to rapid shifts with only a slight change in camera positioning, which can lead to objectionable temporal flicker. Setting this parameter can help mitigate that.
	uvec2 workGroups; // How many workgroups do we have?
	float padding; // Just padding. Might not be needed because std140
};

#define THREADS_X 32
#define THREADS_Y 32

// All the samplers we need!
uniform sampler2D depthMap;
uniform sampler2D normalMap;
uniform sampler2D specularMap;
uniform sampler2D colorMap;

layout (rgba32f) uniform writeonly image2D reflectionImage;

//We can have a maximum of 8 cubemaps blended simultaneously
uniform samplerCube Cubemaps[8];

struct CubemapData
{
	mat4 geometryproxy;
	vec4 cubeMapPosition;
	float blendfactor;
};

uniform uint numCubemaps;

layout(std140, binding = 10) uniform CubeMapBlock
{	
	//how many cubemaps we are currently blending between
	CubemapData cubemapData[8];
};

// Shared values between all the threads in a group
//shared DepthSamples


void GetBlendedCubeMapColor(in vec3 reflectionDir, out vec3 reflectionColor)
{
	vec3 worldDirection = (mat3(InvView) * reflectionDir);
	vec3 cubeColor = vec3(0.0f,0.0f,0.0f);
	
	for(int i = 0; i < numCubemaps; ++i)
	{
		cubeColor += texture(Cubemaps[i], worldDirection).rgb * cubemapData[i].blendfactor;
	}
	
	reflectionColor = cubeColor;
}


void GetBlendedAndParallaxCorrectedCubeMapColor(in float roughness, in vec3 rayPosition, in vec3 reflectionDir, out vec3 reflectionColor)
{
	vec3 cubeColor = vec3(0.0f,0.0f,0.0f);
	
	for(int i = 0; i < numCubemaps; ++i)
	{
		// Intersection with OBB
		// convert to unit box space
		// Transform in local unit parallax cube space (scaled and rotated)
		// Why multiply by 2? Magic.
		vec3 RayLS = (mat3(inverse(cubemapData[i].geometryproxy)) * reflectionDir) * 2.0f;
		vec3 PositionLS = (inverse(cubemapData[i].geometryproxy) * vec4(rayPosition, 1.0f)).xyz * 2.0f;
		
		vec3 Unitary = vec3(1.0f,1.0f,1.0f);
		vec3 FirstPlaneIntersect = (Unitary - PositionLS) / RayLS;
		vec3 SecondPlaneIntersect = (-Unitary - PositionLS) / RayLS;
		vec3 FurthestPlane = max(FirstPlaneIntersect, SecondPlaneIntersect);
		float Distance = min(FurthestPlane.x, min(FurthestPlane.y, FurthestPlane.z));

		// Use Distance in WS directly to recover intersection
		vec3 IntersectPositionWS = rayPosition + reflectionDir * Distance;
		vec3 newWorldDirection = IntersectPositionWS - cubemapData[i].cubeMapPosition.xyz;

		float mipLevel = floor((1 - roughness) * 6);
	
		cubeColor += textureLod(Cubemaps[i], newWorldDirection, mipLevel).rgb * cubemapData[i].blendfactor;
	}
	
	reflectionColor = cubeColor;
}


float distanceSquared(vec2 a, vec2 b)
{
	a -= b;
	return dot(a, a);
}

bool TraceScreenSpaceRay(in vec3 rayOrigin,
						 in vec3 rayDirection,
						 out vec2 hitTexCoord,
						 out vec3 hitPoint
						 )
{
	float nearPlane = -0.05f;

	// Clip to the near plane
	float rayLength = ((rayOrigin.z + rayDirection.z * maxDistance) > nearPlane) ? (nearPlane - rayOrigin.z) / rayDirection.z : maxDistance;

	vec3 rayEnd = rayOrigin + rayDirection * rayLength;

	// Project into homogeneous clip space
	vec4 H0 = ViewToTextureSpace * vec4( rayOrigin, 1.0f);
	vec4 H1 = ViewToTextureSpace * vec4( rayEnd, 1.0f);

	float k0 = 1.0 / H0.w;
	float k1 = 1.0 / H1.w;

	// The interpolated homogeneous version of the camera-space points
	vec3 Q0 = rayOrigin * k0;
	vec3 Q1 = rayEnd * k1;

	// Screen-space endpoints
	vec2 P0 = H0.xy * k0;
	vec2 P1 = H1.xy * k1;

	// If the line is degenerate, make it cover at least one pixel
	// to avoid handling zero-pixel extent as a special case later
	P1 += (distanceSquared(P0, P1) < 0.0001) ? 0.01 : 0.0;

	vec2 delta = P1 - P0;

	// Permute so that the primary iteration is in x to collapse
	// all quadrant-specific DDA cases later
	bool permute = false;

	if (abs(delta.x) < abs(delta.y))
	{
		// This is a more-vertical line
		permute = true;
		delta = delta.yx;
		P0 = P0.yx;
		P1 = P1.yx;
	}

	float stepDir = sign(delta.x);
	float invdx = stepDir / delta.x;

	// Track the derivatives of Q and k
	vec3  dQ = (Q1 - Q0) * invdx;
	float dk = (k1 - k0) * invdx;
	vec2  dP = vec2(stepDir, delta.y * invdx);

	//float strideScaler = 1.0 + min( 1.0, -rayOrigin.z / 100.0f);
	//float pixelStride = 1.0 + strideScaler * stride;

	// Scale derivatives by the desired pixel stride and then
	// offset the starting values by the jitter fraction
	dP *= stride;
	dQ *= stride;
	dk *= stride;
	
	P0 += dP * jitter;
	Q0 += dQ * jitter;
	k0 += dk * jitter;

	float i;
	float zA = 0.0;
	float zB = 0.0;

	// Track ray step and derivatives in a float4 to parallelize
	vec4 pqk = vec4( P0, Q0.z, k0);
	vec4 dPQK = vec4( dP, dQ.z, dk);
	bool intersect = false;

	float end = P1.x * stepDir;

	for(i = 0; i < maxSteps && intersect == false; i++)
	{
		pqk += dPQK;

		zA = zB;
		zB = (dPQK.z * 0.5 + pqk.z) / (dPQK.w * 0.5 + pqk.w);
		if (zB > zA)
		{
			//Swap
			float t = zA;
			zA = zB;
			zB = t;
        }

		hitTexCoord = permute ? pqk.yx : pqk.xy;

		//This doesn't seem necessary anymore...
		// || pqk.x * stepDir >= end
		if(hitTexCoord.x > ScreenSize.x || hitTexCoord.y > ScreenSize.y || hitTexCoord.x < 0 || hitTexCoord.y < 0 || pqk.x * stepDir >= end)
		{
			break;
		}

		float depth = -texelFetch(depthMap, ivec2(hitTexCoord), 0).r;

		intersect = (zB >= depth - zThickness) && (zA <= depth);
	}
	
	
	// Binary search refinement
	if( stride > 1.0 && intersect)
	{
		pqk -= dPQK;
		dPQK /= stride;

		float originalStride = stride * 0.5;
		float stride = originalStride;
		zA = pqk.z / pqk.w;
		zB = zA;
		float j;
		for(j=0; j< 64.0f; j++)
		{
			pqk += dPQK * stride;
			zA = zB;
			zB = (dPQK.z * -0.5 + pqk.z) / (dPQK.w * -0.5 + pqk.w);
			if (zB > zA)
			{
				//Swap
				float t = zA;
				zA = zB;
				zB = t;
			}

			hitTexCoord = permute ? pqk.yx : pqk.xy;

			originalStride *= 0.5;
			stride = (zB <= (-texelFetch(depthMap, ivec2(hitTexCoord), 0).r)) ? -originalStride : originalStride;
		}
	}
	

	Q0.xy += dQ.xy * i;
	Q0.z = pqk.z;
	hitPoint = Q0 / pqk.w;
	//iterationCount = i;

	return intersect;
}

layout(local_size_x = THREADS_X, local_size_y = THREADS_Y, local_size_z = 1) in;
void main()
{
	ivec2 location = ivec2(gl_GlobalInvocationID.xy);

	//Per pixel on depthbuffer

	vec2 TexCoord = vec2(location) / ScreenSize;
	//First of all we need to generate a reflection vector that we can raytrace

	//Get normal from normal map. This only needs to be done once per pixel
	vec3 worldNormal = (texelFetch(normalMap, location, 0).rgb);

	//We need the normal to be in viewspace coordinates.
	vec3 viewSpaceNormal = normalize((View * vec4(worldNormal, 0.0f)).rgb);

	float pixelDepth = texelFetch(depthMap, location, 0).r;

	//Calculate world pos
	vec4 clipSpaceLocation;
	clipSpaceLocation.xy = TexCoord * 2.0f - 1.0f;
	clipSpaceLocation.z = 1.0f;
	clipSpaceLocation.w = 1.0f;
	vec4 homogenousLocation = InvProjection * clipSpaceLocation;
	vec3 viewSpacePosition = homogenousLocation.xyz;

	vec3 rayOrigin = viewSpacePosition * pixelDepth;

	vec3 viewDir = (rayOrigin.xyz);

	//Reflect vector against normal
	vec3 reflectionDir = (reflect(viewDir, viewSpaceNormal));

	vec2 hitTexCoord = vec2(0.0,0.0);
	vec3 hitPoint = vec3(0.0,0.0,0.0);

	vec4 specularAndRoughness = texelFetch(specularMap, location, 0).rgba;
	float roughness = specularAndRoughness.w;
	vec4 BGColor = texelFetch(colorMap, location, 0).rgba;
	
	vec3 reflectionColor;
	
	
	if (TraceScreenSpaceRay(rayOrigin.xyz, reflectionDir, hitTexCoord, hitPoint))
	{
		reflectionColor = texelFetch(colorMap, ivec2(hitTexCoord), 0).rgb;
	}
	else
	{
		//Get fall-back value.
		//GetBlendedCubeMapColor(reflectionDir, reflectionColor);
		
		vec3 worldPosition = (InvView * vec4(rayOrigin, 1.0f)).xyz;
		vec3 worldDirection = normalize(mat3(InvView) * reflectionDir);
		GetBlendedAndParallaxCorrectedCubeMapColor(roughness, worldPosition, worldDirection, reflectionColor);
		//reflectionColor = vec3(1.0f,0.0,0.0);
	}

	vec4 finalColor = vec4((BGColor.rgb * (1-specularAndRoughness.r)) + (reflectionColor.rgb * specularAndRoughness.r), BGColor.a);
	//vec4 finalColor = vec4(reflectionColor, 1.0f);
	imageStore(reflectionImage, location, finalColor);
	
	groupMemoryBarrier();
}
